{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.0\n",
      "Torchvision Version:  0.6.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy \n",
    "import random\n",
    "import shutil, sys\n",
    "import pandas as pd\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = '/home/jimi/dissertacao/covid19/datasets/dataset_bal/'\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"densenet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 3\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 200\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files per classes\n",
      "----------------------------------------\n",
      "normal :  505\n",
      "pneumonia :  505\n",
      "covid :  505\n",
      "--------------------\n",
      "Train, test, validation\n",
      "--------------------\n",
      "len_train_dir :  969\n",
      "len_test_dir :  303\n",
      "len_val_dir :  243\n"
     ]
    }
   ],
   "source": [
    "# Path to data\n",
    "data_dir = '/home/jimi/dissertacao/covid19/datasets/dataset_bal/'\n",
    "train_dir = data_dir+'train/'\n",
    "test_dir = data_dir+'test/'\n",
    "val_dir = data_dir+'val/'\n",
    "\n",
    "normal_dir = data_dir+'normal/'\n",
    "pneumonia_dir = data_dir+'pneumonia/'\n",
    "covid_dir = data_dir+'covid/'\n",
    "\n",
    "len_covid = len([iq for iq in os.scandir(normal_dir)])\n",
    "len_normal = len([iq for iq in os.scandir(pneumonia_dir)])\n",
    "len_pneumonia = len([iq for iq in os.scandir(covid_dir)])\n",
    "\n",
    "len_train_dir = len([iq for iq in os.scandir(train_dir+'covid/')]) + len([iq for iq in os.scandir(train_dir+'normal/')]) + len([iq for iq in os.scandir(train_dir+'pneumonia/')])\n",
    "len_test_dir = len([iq for iq in os.scandir(test_dir+'covid/')]) + len([iq for iq in os.scandir(test_dir+'normal/')]) + len([iq for iq in os.scandir(test_dir+'pneumonia/')])\n",
    "len_val_dir = len([iq for iq in os.scandir(val_dir+'covid/')]) + len([iq for iq in os.scandir(val_dir+'normal/')]) + len([iq for iq in os.scandir(val_dir+'pneumonia/')])\n",
    "\n",
    "print('Files per classes')\n",
    "print(\"----\"*10)\n",
    "print(\"normal : \", len_covid)\n",
    "print(\"pneumonia : \", len_normal)\n",
    "print(\"covid : \", len_pneumonia)\n",
    "print(\"-\"*20)\n",
    "print('Train, test, validation')\n",
    "print(\"-\"*20)\n",
    "print(\"len_train_dir : \", len_train_dir)\n",
    "print(\"len_test_dir : \", len_test_dir)\n",
    "print(\"len_val_dir : \", len_val_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "#transforms.RandomRotation(degrees=(-5, 5)),\n",
    "#transforms.ColorJitter(brightness=.02),\n",
    "    \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.weight\n",
      "\t classifier.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 0.7480 Acc: 0.6667\n",
      "val Loss: 0.3990 Acc: 0.8971\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 0.5269 Acc: 0.7895\n",
      "val Loss: 0.3590 Acc: 0.8971\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 0.4763 Acc: 0.8070\n",
      "val Loss: 0.3715 Acc: 0.8519\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 0.4721 Acc: 0.8142\n",
      "val Loss: 0.4742 Acc: 0.8189\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 0.4497 Acc: 0.8215\n",
      "val Loss: 0.2637 Acc: 0.9218\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 0.4901 Acc: 0.8050\n",
      "val Loss: 0.3008 Acc: 0.8889\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 0.4797 Acc: 0.8194\n",
      "val Loss: 0.2349 Acc: 0.9342\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 0.4315 Acc: 0.8318\n",
      "val Loss: 0.2846 Acc: 0.9053\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 0.4004 Acc: 0.8400\n",
      "val Loss: 0.2345 Acc: 0.9259\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 0.4751 Acc: 0.8215\n",
      "val Loss: 0.2159 Acc: 0.9342\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 0.3672 Acc: 0.8586\n",
      "val Loss: 0.3115 Acc: 0.9136\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 0.4070 Acc: 0.8411\n",
      "val Loss: 0.2655 Acc: 0.9136\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 0.4021 Acc: 0.8452\n",
      "val Loss: 0.3119 Acc: 0.9053\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 0.4370 Acc: 0.8421\n",
      "val Loss: 0.2161 Acc: 0.9383\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 0.3819 Acc: 0.8545\n",
      "val Loss: 0.1952 Acc: 0.9547\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 0.4010 Acc: 0.8452\n",
      "val Loss: 0.2815 Acc: 0.8848\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 0.3776 Acc: 0.8473\n",
      "val Loss: 0.1921 Acc: 0.9465\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 0.3604 Acc: 0.8731\n",
      "val Loss: 0.1903 Acc: 0.9506\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 0.3522 Acc: 0.8751\n",
      "val Loss: 0.2073 Acc: 0.9342\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 0.3524 Acc: 0.8596\n",
      "val Loss: 0.2804 Acc: 0.9177\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 0.3892 Acc: 0.8493\n",
      "val Loss: 0.2391 Acc: 0.9259\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 0.3398 Acc: 0.8782\n",
      "val Loss: 0.3287 Acc: 0.8807\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 0.3241 Acc: 0.8813\n",
      "val Loss: 0.3202 Acc: 0.8807\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 0.3828 Acc: 0.8545\n",
      "val Loss: 0.1961 Acc: 0.9424\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 0.3822 Acc: 0.8535\n",
      "val Loss: 0.2658 Acc: 0.9095\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 0.3557 Acc: 0.8710\n",
      "val Loss: 0.3261 Acc: 0.8971\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 0.4300 Acc: 0.8452\n",
      "val Loss: 0.1902 Acc: 0.9342\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 0.3889 Acc: 0.8359\n",
      "val Loss: 0.2883 Acc: 0.8848\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 0.4123 Acc: 0.8586\n",
      "val Loss: 0.1901 Acc: 0.9342\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 0.4044 Acc: 0.8566\n",
      "val Loss: 0.2455 Acc: 0.9218\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 0.3811 Acc: 0.8431\n",
      "val Loss: 0.2043 Acc: 0.9342\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 0.3805 Acc: 0.8545\n",
      "val Loss: 0.1881 Acc: 0.9383\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 0.3352 Acc: 0.8762\n",
      "val Loss: 0.1645 Acc: 0.9506\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 0.3735 Acc: 0.8596\n",
      "val Loss: 0.1929 Acc: 0.9465\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 0.3654 Acc: 0.8504\n",
      "val Loss: 0.1713 Acc: 0.9465\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 0.3310 Acc: 0.8731\n",
      "val Loss: 0.1835 Acc: 0.9342\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 0.3961 Acc: 0.8566\n",
      "val Loss: 0.2134 Acc: 0.9259\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 0.3432 Acc: 0.8834\n",
      "val Loss: 0.2584 Acc: 0.9053\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 0.3979 Acc: 0.8566\n",
      "val Loss: 0.1751 Acc: 0.9547\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 0.3792 Acc: 0.8607\n",
      "val Loss: 0.3426 Acc: 0.8765\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 0.3923 Acc: 0.8483\n",
      "val Loss: 0.1841 Acc: 0.9506\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 0.3340 Acc: 0.8710\n",
      "val Loss: 0.1728 Acc: 0.9465\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 0.3123 Acc: 0.8772\n",
      "val Loss: 0.1725 Acc: 0.9383\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 0.3243 Acc: 0.8762\n",
      "val Loss: 0.1702 Acc: 0.9465\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 0.3924 Acc: 0.8514\n",
      "val Loss: 0.2562 Acc: 0.9095\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 0.3066 Acc: 0.8854\n",
      "val Loss: 0.1872 Acc: 0.9300\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 0.4006 Acc: 0.8617\n",
      "val Loss: 0.1731 Acc: 0.9424\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 0.3198 Acc: 0.8916\n",
      "val Loss: 0.1814 Acc: 0.9465\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 0.3532 Acc: 0.8596\n",
      "val Loss: 0.2256 Acc: 0.9218\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 0.3806 Acc: 0.8535\n",
      "val Loss: 0.1873 Acc: 0.9383\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 0.3443 Acc: 0.8813\n",
      "val Loss: 0.1687 Acc: 0.9424\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 0.3429 Acc: 0.8751\n",
      "val Loss: 0.1721 Acc: 0.9424\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 0.3890 Acc: 0.8535\n",
      "val Loss: 0.1807 Acc: 0.9506\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 0.2985 Acc: 0.8906\n",
      "val Loss: 0.2299 Acc: 0.9218\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 0.3852 Acc: 0.8514\n",
      "val Loss: 0.1950 Acc: 0.9300\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 0.2984 Acc: 0.8927\n",
      "val Loss: 0.1622 Acc: 0.9547\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 0.3672 Acc: 0.8493\n",
      "val Loss: 0.1947 Acc: 0.9300\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 0.3533 Acc: 0.8741\n",
      "val Loss: 0.2033 Acc: 0.9424\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 0.3497 Acc: 0.8720\n",
      "val Loss: 0.1706 Acc: 0.9424\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 0.4470 Acc: 0.8390\n",
      "val Loss: 0.2404 Acc: 0.9136\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 0.3831 Acc: 0.8411\n",
      "val Loss: 0.1960 Acc: 0.9259\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 0.3305 Acc: 0.8689\n",
      "val Loss: 0.2089 Acc: 0.9259\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 0.3380 Acc: 0.8813\n",
      "val Loss: 0.2182 Acc: 0.9259\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 0.4201 Acc: 0.8462\n",
      "val Loss: 0.1741 Acc: 0.9383\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 0.3082 Acc: 0.8865\n",
      "val Loss: 0.1863 Acc: 0.9424\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 0.3037 Acc: 0.8793\n",
      "val Loss: 0.4040 Acc: 0.8519\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 0.3429 Acc: 0.8576\n",
      "val Loss: 0.1864 Acc: 0.9300\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 0.3280 Acc: 0.8793\n",
      "val Loss: 0.2224 Acc: 0.9177\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 0.3141 Acc: 0.8896\n",
      "val Loss: 0.1896 Acc: 0.9383\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 0.3302 Acc: 0.8762\n",
      "val Loss: 0.1710 Acc: 0.9465\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 0.3959 Acc: 0.8576\n",
      "val Loss: 0.1819 Acc: 0.9424\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 0.3314 Acc: 0.8731\n",
      "val Loss: 0.1801 Acc: 0.9259\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 0.3564 Acc: 0.8762\n",
      "val Loss: 0.3875 Acc: 0.8395\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 0.3428 Acc: 0.8700\n",
      "val Loss: 0.2068 Acc: 0.9177\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 0.3627 Acc: 0.8596\n",
      "val Loss: 0.1741 Acc: 0.9342\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 0.3062 Acc: 0.8751\n",
      "val Loss: 0.1732 Acc: 0.9506\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 0.3085 Acc: 0.8700\n",
      "val Loss: 0.2255 Acc: 0.9095\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 0.4237 Acc: 0.8483\n",
      "val Loss: 0.1643 Acc: 0.9383\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 0.3852 Acc: 0.8535\n",
      "val Loss: 0.1757 Acc: 0.9300\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 0.3624 Acc: 0.8700\n",
      "val Loss: 0.1956 Acc: 0.9383\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 0.3355 Acc: 0.8679\n",
      "val Loss: 0.1995 Acc: 0.9300\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 0.3394 Acc: 0.8638\n",
      "val Loss: 0.2123 Acc: 0.9259\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 0.3168 Acc: 0.8854\n",
      "val Loss: 0.1623 Acc: 0.9547\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 0.3262 Acc: 0.8679\n",
      "val Loss: 0.2180 Acc: 0.9177\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 0.3084 Acc: 0.8813\n",
      "val Loss: 0.2244 Acc: 0.9259\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 0.3337 Acc: 0.8875\n",
      "val Loss: 0.2634 Acc: 0.9095\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 0.4193 Acc: 0.8390\n",
      "val Loss: 0.2603 Acc: 0.9177\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 0.4023 Acc: 0.8524\n",
      "val Loss: 0.2125 Acc: 0.9259\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 0.3166 Acc: 0.8772\n",
      "val Loss: 0.1796 Acc: 0.9259\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 0.3376 Acc: 0.8679\n",
      "val Loss: 0.1725 Acc: 0.9383\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 0.3681 Acc: 0.8535\n",
      "val Loss: 0.1970 Acc: 0.9342\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 0.3458 Acc: 0.8720\n",
      "val Loss: 0.2077 Acc: 0.9259\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 0.3598 Acc: 0.8700\n",
      "val Loss: 0.1644 Acc: 0.9465\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 0.4067 Acc: 0.8400\n",
      "val Loss: 0.1758 Acc: 0.9383\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 0.4377 Acc: 0.8390\n",
      "val Loss: 0.1914 Acc: 0.9383\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 0.3350 Acc: 0.8793\n",
      "val Loss: 0.1927 Acc: 0.9300\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 0.3191 Acc: 0.8772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1747 Acc: 0.9383\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 0.3798 Acc: 0.8679\n",
      "val Loss: 0.2535 Acc: 0.9136\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 0.3394 Acc: 0.8772\n",
      "val Loss: 0.1517 Acc: 0.9506\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 0.4206 Acc: 0.8545\n",
      "val Loss: 0.1988 Acc: 0.9300\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 0.3446 Acc: 0.8689\n",
      "val Loss: 0.1474 Acc: 0.9506\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 0.2773 Acc: 0.9040\n",
      "val Loss: 0.2771 Acc: 0.8971\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 0.3595 Acc: 0.8710\n",
      "val Loss: 0.2062 Acc: 0.9383\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 0.3825 Acc: 0.8514\n",
      "val Loss: 0.1827 Acc: 0.9506\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 0.3255 Acc: 0.8803\n",
      "val Loss: 0.2285 Acc: 0.9300\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 0.3240 Acc: 0.8906\n",
      "val Loss: 0.1247 Acc: 0.9671\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 0.2962 Acc: 0.8875\n",
      "val Loss: 0.1694 Acc: 0.9506\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 0.4286 Acc: 0.8483\n",
      "val Loss: 0.1513 Acc: 0.9547\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 0.3850 Acc: 0.8493\n",
      "val Loss: 0.2785 Acc: 0.8930\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 0.3601 Acc: 0.8710\n",
      "val Loss: 0.1782 Acc: 0.9465\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 0.3488 Acc: 0.8689\n",
      "val Loss: 0.1777 Acc: 0.9383\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 0.3663 Acc: 0.8617\n",
      "val Loss: 0.2568 Acc: 0.9012\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 0.3618 Acc: 0.8679\n",
      "val Loss: 0.1687 Acc: 0.9342\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 0.3837 Acc: 0.8596\n",
      "val Loss: 0.1820 Acc: 0.9342\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 0.3389 Acc: 0.8731\n",
      "val Loss: 0.1511 Acc: 0.9547\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 0.3398 Acc: 0.8689\n",
      "val Loss: 0.1936 Acc: 0.9424\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 0.3403 Acc: 0.8627\n",
      "val Loss: 0.1600 Acc: 0.9424\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 0.3419 Acc: 0.8700\n",
      "val Loss: 0.2578 Acc: 0.8971\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 0.3468 Acc: 0.8679\n",
      "val Loss: 0.2803 Acc: 0.9012\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 0.3385 Acc: 0.8813\n",
      "val Loss: 0.1784 Acc: 0.9300\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 0.3087 Acc: 0.8844\n",
      "val Loss: 0.1515 Acc: 0.9424\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 0.3146 Acc: 0.8762\n",
      "val Loss: 0.1881 Acc: 0.9342\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 0.3178 Acc: 0.8906\n",
      "val Loss: 0.1651 Acc: 0.9424\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 0.3320 Acc: 0.8751\n",
      "val Loss: 0.1449 Acc: 0.9465\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 0.3391 Acc: 0.8793\n",
      "val Loss: 0.1826 Acc: 0.9342\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 0.3431 Acc: 0.8669\n",
      "val Loss: 0.2879 Acc: 0.8848\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 0.3554 Acc: 0.8669\n",
      "val Loss: 0.2066 Acc: 0.9136\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 0.3256 Acc: 0.8813\n",
      "val Loss: 0.1682 Acc: 0.9424\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 0.3941 Acc: 0.8689\n",
      "val Loss: 0.1727 Acc: 0.9259\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 0.3355 Acc: 0.8741\n",
      "val Loss: 0.2057 Acc: 0.9218\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 0.3812 Acc: 0.8555\n",
      "val Loss: 0.2480 Acc: 0.9012\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 0.3311 Acc: 0.8710\n",
      "val Loss: 0.1686 Acc: 0.9300\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 0.3284 Acc: 0.8803\n",
      "val Loss: 0.2764 Acc: 0.8889\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 0.2928 Acc: 0.8896\n",
      "val Loss: 0.1681 Acc: 0.9424\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 0.3697 Acc: 0.8617\n",
      "val Loss: 0.1637 Acc: 0.9424\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 0.3149 Acc: 0.8916\n",
      "val Loss: 0.1554 Acc: 0.9465\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 0.3999 Acc: 0.8596\n",
      "val Loss: 0.1943 Acc: 0.9383\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.2908 Acc: 0.8772\n",
      "val Loss: 0.1845 Acc: 0.9383\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 0.3755 Acc: 0.8658\n",
      "val Loss: 0.2390 Acc: 0.9177\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 0.3511 Acc: 0.8679\n",
      "val Loss: 0.2034 Acc: 0.9259\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 0.3413 Acc: 0.8700\n",
      "val Loss: 0.2902 Acc: 0.8889\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.3743 Acc: 0.8596\n",
      "val Loss: 0.2563 Acc: 0.8889\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.2918 Acc: 0.8947\n",
      "val Loss: 0.2311 Acc: 0.9218\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.3443 Acc: 0.8813\n",
      "val Loss: 0.2231 Acc: 0.9300\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.3542 Acc: 0.8782\n",
      "val Loss: 0.1451 Acc: 0.9547\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.3599 Acc: 0.8679\n",
      "val Loss: 0.1836 Acc: 0.9383\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.3236 Acc: 0.8875\n",
      "val Loss: 0.2025 Acc: 0.9218\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.2926 Acc: 0.8989\n",
      "val Loss: 0.2365 Acc: 0.9218\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.3137 Acc: 0.8834\n",
      "val Loss: 0.2906 Acc: 0.8889\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.3092 Acc: 0.8751\n",
      "val Loss: 0.1588 Acc: 0.9506\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.3347 Acc: 0.8772\n",
      "val Loss: 0.3399 Acc: 0.8642\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.3233 Acc: 0.8741\n",
      "val Loss: 0.2187 Acc: 0.9259\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.3326 Acc: 0.8720\n",
      "val Loss: 0.1838 Acc: 0.9342\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.2986 Acc: 0.8906\n",
      "val Loss: 0.2354 Acc: 0.8971\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.3128 Acc: 0.8865\n",
      "val Loss: 0.1796 Acc: 0.9300\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.3486 Acc: 0.8679\n",
      "val Loss: 0.2531 Acc: 0.9012\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.3265 Acc: 0.8751\n",
      "val Loss: 0.2731 Acc: 0.8971\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.3329 Acc: 0.8772\n",
      "val Loss: 0.1495 Acc: 0.9465\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.2945 Acc: 0.8906\n",
      "val Loss: 0.1839 Acc: 0.9424\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.3927 Acc: 0.8617\n",
      "val Loss: 0.1559 Acc: 0.9342\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.3744 Acc: 0.8596\n",
      "val Loss: 0.2334 Acc: 0.9095\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.3774 Acc: 0.8442\n",
      "val Loss: 0.4461 Acc: 0.8272\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.3426 Acc: 0.8762\n",
      "val Loss: 0.3314 Acc: 0.8765\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.3954 Acc: 0.8504\n",
      "val Loss: 0.2895 Acc: 0.8848\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.3449 Acc: 0.8710\n",
      "val Loss: 0.1985 Acc: 0.9342\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 0.3433 Acc: 0.8751\n",
      "val Loss: 0.1801 Acc: 0.9424\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 0.3179 Acc: 0.8813\n",
      "val Loss: 0.1331 Acc: 0.9671\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 0.3644 Acc: 0.8710\n",
      "val Loss: 0.1422 Acc: 0.9547\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 0.3367 Acc: 0.8762\n",
      "val Loss: 0.2440 Acc: 0.9053\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 0.3170 Acc: 0.8762\n",
      "val Loss: 0.1790 Acc: 0.9547\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 0.3488 Acc: 0.8669\n",
      "val Loss: 0.2153 Acc: 0.9259\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 0.3596 Acc: 0.8751\n",
      "val Loss: 0.1781 Acc: 0.9342\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 0.3286 Acc: 0.8741\n",
      "val Loss: 0.2109 Acc: 0.9136\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 0.3751 Acc: 0.8627\n",
      "val Loss: 0.2052 Acc: 0.9218\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 0.3503 Acc: 0.8679\n",
      "val Loss: 0.1908 Acc: 0.9177\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 0.3459 Acc: 0.8813\n",
      "val Loss: 0.1476 Acc: 0.9465\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 0.3477 Acc: 0.8669\n",
      "val Loss: 0.1598 Acc: 0.9588\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 0.3328 Acc: 0.8710\n",
      "val Loss: 0.2329 Acc: 0.9053\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 0.4018 Acc: 0.8576\n",
      "val Loss: 0.4783 Acc: 0.8148\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 0.3573 Acc: 0.8627\n",
      "val Loss: 0.1616 Acc: 0.9547\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 0.3834 Acc: 0.8514\n",
      "val Loss: 0.2820 Acc: 0.8971\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 0.3357 Acc: 0.8751\n",
      "val Loss: 0.2933 Acc: 0.8683\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 0.3842 Acc: 0.8669\n",
      "val Loss: 0.1944 Acc: 0.9300\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 0.3526 Acc: 0.8803\n",
      "val Loss: 0.1921 Acc: 0.9259\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 0.3708 Acc: 0.8627\n",
      "val Loss: 0.2383 Acc: 0.9053\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 0.3756 Acc: 0.8514\n",
      "val Loss: 0.1490 Acc: 0.9424\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 0.3522 Acc: 0.8710\n",
      "val Loss: 0.2242 Acc: 0.9259\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 0.3733 Acc: 0.8700\n",
      "val Loss: 0.1957 Acc: 0.9259\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 0.3398 Acc: 0.8689\n",
      "val Loss: 0.2323 Acc: 0.9218\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 0.3863 Acc: 0.8555\n",
      "val Loss: 0.2940 Acc: 0.8889\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 0.3515 Acc: 0.8741\n",
      "val Loss: 0.1823 Acc: 0.9259\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 0.3143 Acc: 0.8762\n",
      "val Loss: 0.1645 Acc: 0.9506\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3274 Acc: 0.8854\n",
      "val Loss: 0.1494 Acc: 0.9465\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 0.3190 Acc: 0.8844\n",
      "val Loss: 0.1552 Acc: 0.9465\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 0.2792 Acc: 0.8968\n",
      "val Loss: 0.3583 Acc: 0.8807\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 0.2823 Acc: 0.8958\n",
      "val Loss: 0.1864 Acc: 0.9383\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 0.3153 Acc: 0.8731\n",
      "val Loss: 0.1852 Acc: 0.9424\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 0.3113 Acc: 0.8844\n",
      "val Loss: 0.1635 Acc: 0.9547\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 0.3469 Acc: 0.8720\n",
      "val Loss: 0.2127 Acc: 0.9218\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 0.3265 Acc: 0.8731\n",
      "val Loss: 0.2813 Acc: 0.8971\n",
      "\n",
      "Training complete in 114m 53s\n",
      "Best val Acc: 0.967078\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, \n",
    "                             optimizer_ft, num_epochs=num_epochs, \n",
    "                             is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
