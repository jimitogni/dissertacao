{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.0\n",
      "Torchvision Version:  0.6.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy \n",
    "import random\n",
    "import shutil, sys\n",
    "import pandas as pd\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = '/home/jimi/dissertacao/covid19/datasets/dataset_bal/'\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"densenet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 3\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 200\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files per classes\n",
      "----------------------------------------\n",
      "normal :  505\n",
      "pneumonia :  505\n",
      "covid :  505\n",
      "--------------------\n",
      "Train, test, validation\n",
      "--------------------\n",
      "len_train_dir :  969\n",
      "len_test_dir :  303\n",
      "len_val_dir :  243\n"
     ]
    }
   ],
   "source": [
    "# Path to data\n",
    "data_dir = '/home/jimi/dissertacao/covid19/datasets/dataset_bal/'\n",
    "train_dir = data_dir+'train/'\n",
    "test_dir = data_dir+'test/'\n",
    "val_dir = data_dir+'val/'\n",
    "\n",
    "normal_dir = data_dir+'normal/'\n",
    "pneumonia_dir = data_dir+'pneumonia/'\n",
    "covid_dir = data_dir+'covid/'\n",
    "\n",
    "len_covid = len([iq for iq in os.scandir(normal_dir)])\n",
    "len_normal = len([iq for iq in os.scandir(pneumonia_dir)])\n",
    "len_pneumonia = len([iq for iq in os.scandir(covid_dir)])\n",
    "\n",
    "len_train_dir = len([iq for iq in os.scandir(train_dir+'covid/')]) + len([iq for iq in os.scandir(train_dir+'normal/')]) + len([iq for iq in os.scandir(train_dir+'pneumonia/')])\n",
    "len_test_dir = len([iq for iq in os.scandir(test_dir+'covid/')]) + len([iq for iq in os.scandir(test_dir+'normal/')]) + len([iq for iq in os.scandir(test_dir+'pneumonia/')])\n",
    "len_val_dir = len([iq for iq in os.scandir(val_dir+'covid/')]) + len([iq for iq in os.scandir(val_dir+'normal/')]) + len([iq for iq in os.scandir(val_dir+'pneumonia/')])\n",
    "\n",
    "print('Files per classes')\n",
    "print(\"----\"*10)\n",
    "print(\"normal : \", len_covid)\n",
    "print(\"pneumonia : \", len_normal)\n",
    "print(\"covid : \", len_pneumonia)\n",
    "print(\"-\"*20)\n",
    "print('Train, test, validation')\n",
    "print(\"-\"*20)\n",
    "print(\"len_train_dir : \", len_train_dir)\n",
    "print(\"len_test_dir : \", len_test_dir)\n",
    "print(\"len_val_dir : \", len_val_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "#transforms.RandomRotation(degrees=(-5, 5)),\n",
    "#transforms.ColorJitter(brightness=.02),\n",
    "    \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(degrees=(-10, 10)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.weight\n",
      "\t classifier.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 0.7954 Acc: 0.6367\n",
      "val Loss: 0.4558 Acc: 0.9012\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 0.5959 Acc: 0.7399\n",
      "val Loss: 0.3784 Acc: 0.8971\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 0.5065 Acc: 0.8060\n",
      "val Loss: 0.3531 Acc: 0.9012\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 0.5610 Acc: 0.7750\n",
      "val Loss: 0.4526 Acc: 0.8519\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 0.4869 Acc: 0.8091\n",
      "val Loss: 0.3447 Acc: 0.8971\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 0.4792 Acc: 0.7957\n",
      "val Loss: 0.3032 Acc: 0.9095\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 0.4802 Acc: 0.8039\n",
      "val Loss: 0.3254 Acc: 0.8930\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 0.5367 Acc: 0.7843\n",
      "val Loss: 0.3160 Acc: 0.8889\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 0.4677 Acc: 0.8060\n",
      "val Loss: 0.4305 Acc: 0.8395\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 0.4332 Acc: 0.8215\n",
      "val Loss: 0.2566 Acc: 0.9136\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 0.4341 Acc: 0.8256\n",
      "val Loss: 0.3472 Acc: 0.8765\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 0.4404 Acc: 0.8308\n",
      "val Loss: 0.2780 Acc: 0.8971\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 0.4459 Acc: 0.8380\n",
      "val Loss: 0.2944 Acc: 0.9095\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 0.4487 Acc: 0.8246\n",
      "val Loss: 0.2531 Acc: 0.9136\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 0.3952 Acc: 0.8349\n",
      "val Loss: 0.2645 Acc: 0.9095\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 0.4277 Acc: 0.8359\n",
      "val Loss: 0.3221 Acc: 0.8930\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 0.4161 Acc: 0.8380\n",
      "val Loss: 0.3110 Acc: 0.9012\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 0.4274 Acc: 0.8338\n",
      "val Loss: 0.2614 Acc: 0.9053\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 0.4091 Acc: 0.8338\n",
      "val Loss: 0.3438 Acc: 0.8683\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 0.5423 Acc: 0.7833\n",
      "val Loss: 0.2700 Acc: 0.9095\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 0.4575 Acc: 0.8194\n",
      "val Loss: 0.2600 Acc: 0.9095\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 0.4092 Acc: 0.8411\n",
      "val Loss: 0.2406 Acc: 0.9177\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 0.4081 Acc: 0.8359\n",
      "val Loss: 0.2797 Acc: 0.8848\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 0.4186 Acc: 0.8318\n",
      "val Loss: 0.2396 Acc: 0.9177\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 0.4308 Acc: 0.8369\n",
      "val Loss: 0.2937 Acc: 0.9053\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 0.4225 Acc: 0.8318\n",
      "val Loss: 0.2327 Acc: 0.9218\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 0.4273 Acc: 0.8235\n",
      "val Loss: 0.2434 Acc: 0.9177\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 0.4701 Acc: 0.8101\n",
      "val Loss: 0.3221 Acc: 0.8848\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 0.4332 Acc: 0.8318\n",
      "val Loss: 0.2798 Acc: 0.8971\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 0.4275 Acc: 0.8359\n",
      "val Loss: 0.2428 Acc: 0.9300\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 0.4555 Acc: 0.8452\n",
      "val Loss: 0.3292 Acc: 0.8436\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 0.4049 Acc: 0.8545\n",
      "val Loss: 0.2533 Acc: 0.9259\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 0.4034 Acc: 0.8483\n",
      "val Loss: 0.2170 Acc: 0.9383\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 0.4553 Acc: 0.8215\n",
      "val Loss: 0.2376 Acc: 0.9300\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 0.4028 Acc: 0.8328\n",
      "val Loss: 0.2679 Acc: 0.9095\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 0.4225 Acc: 0.8277\n",
      "val Loss: 0.2147 Acc: 0.9095\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 0.4156 Acc: 0.8462\n",
      "val Loss: 0.2337 Acc: 0.9177\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 0.3684 Acc: 0.8586\n",
      "val Loss: 0.2102 Acc: 0.9177\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 0.4377 Acc: 0.8308\n",
      "val Loss: 0.2260 Acc: 0.9177\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 0.4021 Acc: 0.8473\n",
      "val Loss: 0.1939 Acc: 0.9383\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 0.3895 Acc: 0.8504\n",
      "val Loss: 0.2233 Acc: 0.9177\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 0.4370 Acc: 0.8462\n",
      "val Loss: 0.2622 Acc: 0.8889\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 0.3909 Acc: 0.8442\n",
      "val Loss: 0.2271 Acc: 0.9218\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 0.3875 Acc: 0.8390\n",
      "val Loss: 0.2161 Acc: 0.9012\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 0.4151 Acc: 0.8328\n",
      "val Loss: 0.2218 Acc: 0.9177\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 0.3568 Acc: 0.8576\n",
      "val Loss: 0.2426 Acc: 0.9177\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 0.3756 Acc: 0.8576\n",
      "val Loss: 0.2668 Acc: 0.8889\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 0.4489 Acc: 0.8266\n",
      "val Loss: 0.2457 Acc: 0.9136\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 0.4084 Acc: 0.8586\n",
      "val Loss: 0.2962 Acc: 0.8683\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 0.3937 Acc: 0.8566\n",
      "val Loss: 0.3385 Acc: 0.8601\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 0.5368 Acc: 0.8060\n",
      "val Loss: 0.2266 Acc: 0.9342\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 0.4170 Acc: 0.8359\n",
      "val Loss: 0.3285 Acc: 0.8724\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 0.3859 Acc: 0.8359\n",
      "val Loss: 0.2906 Acc: 0.8848\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 0.4133 Acc: 0.8411\n",
      "val Loss: 0.2774 Acc: 0.8971\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 0.3539 Acc: 0.8586\n",
      "val Loss: 0.2688 Acc: 0.8807\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 0.4851 Acc: 0.8184\n",
      "val Loss: 0.3317 Acc: 0.8683\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 0.4194 Acc: 0.8421\n",
      "val Loss: 0.2725 Acc: 0.9012\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 0.4494 Acc: 0.8256\n",
      "val Loss: 0.2611 Acc: 0.8930\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 0.4592 Acc: 0.8338\n",
      "val Loss: 0.2687 Acc: 0.8889\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 0.4686 Acc: 0.8297\n",
      "val Loss: 0.2217 Acc: 0.9259\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 0.3715 Acc: 0.8669\n",
      "val Loss: 0.2444 Acc: 0.9177\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 0.4516 Acc: 0.8411\n",
      "val Loss: 0.3987 Acc: 0.8601\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 0.3882 Acc: 0.8473\n",
      "val Loss: 0.2971 Acc: 0.8848\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 0.3339 Acc: 0.8731\n",
      "val Loss: 0.2140 Acc: 0.9259\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 0.3672 Acc: 0.8617\n",
      "val Loss: 0.2159 Acc: 0.9259\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 0.4383 Acc: 0.8338\n",
      "val Loss: 0.2556 Acc: 0.9095\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 0.4257 Acc: 0.8380\n",
      "val Loss: 0.3187 Acc: 0.8765\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 0.3963 Acc: 0.8349\n",
      "val Loss: 0.2600 Acc: 0.9053\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 0.4490 Acc: 0.8184\n",
      "val Loss: 0.2865 Acc: 0.9177\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 0.3441 Acc: 0.8741\n",
      "val Loss: 0.2519 Acc: 0.9095\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 0.4257 Acc: 0.8421\n",
      "val Loss: 0.2191 Acc: 0.9218\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 0.4177 Acc: 0.8400\n",
      "val Loss: 0.2670 Acc: 0.8848\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 0.3964 Acc: 0.8555\n",
      "val Loss: 0.3353 Acc: 0.8807\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 0.4345 Acc: 0.8411\n",
      "val Loss: 0.4880 Acc: 0.8477\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 0.3430 Acc: 0.8638\n",
      "val Loss: 0.2990 Acc: 0.8930\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 0.4001 Acc: 0.8566\n",
      "val Loss: 0.3312 Acc: 0.8807\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 0.3294 Acc: 0.8493\n",
      "val Loss: 0.2639 Acc: 0.8930\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 0.3683 Acc: 0.8700\n",
      "val Loss: 0.2189 Acc: 0.9259\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 0.4494 Acc: 0.8287\n",
      "val Loss: 0.3786 Acc: 0.8230\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 0.3722 Acc: 0.8669\n",
      "val Loss: 0.2208 Acc: 0.9053\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 0.4838 Acc: 0.8184\n",
      "val Loss: 0.3102 Acc: 0.8519\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 0.3857 Acc: 0.8566\n",
      "val Loss: 0.3046 Acc: 0.8930\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 0.4360 Acc: 0.8421\n",
      "val Loss: 0.2269 Acc: 0.9259\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 0.3929 Acc: 0.8390\n",
      "val Loss: 0.3013 Acc: 0.8560\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 0.4487 Acc: 0.8215\n",
      "val Loss: 0.2272 Acc: 0.9177\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 0.3778 Acc: 0.8462\n",
      "val Loss: 0.2222 Acc: 0.9342\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 0.4060 Acc: 0.8400\n",
      "val Loss: 0.4553 Acc: 0.8519\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 0.4218 Acc: 0.8359\n",
      "val Loss: 0.3970 Acc: 0.8519\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 0.3946 Acc: 0.8607\n",
      "val Loss: 0.2390 Acc: 0.9095\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 0.4100 Acc: 0.8596\n",
      "val Loss: 0.2509 Acc: 0.9177\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 0.3640 Acc: 0.8535\n",
      "val Loss: 0.2424 Acc: 0.8765\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 0.4607 Acc: 0.8235\n",
      "val Loss: 0.2393 Acc: 0.9053\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 0.4657 Acc: 0.8153\n",
      "val Loss: 0.2291 Acc: 0.9136\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 0.3792 Acc: 0.8524\n",
      "val Loss: 0.2015 Acc: 0.9300\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 0.3779 Acc: 0.8514\n",
      "val Loss: 0.2359 Acc: 0.9095\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 0.3987 Acc: 0.8473\n",
      "val Loss: 0.2319 Acc: 0.9300\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 0.4293 Acc: 0.8287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2310 Acc: 0.9218\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 0.4052 Acc: 0.8442\n",
      "val Loss: 0.3832 Acc: 0.8601\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 0.4093 Acc: 0.8380\n",
      "val Loss: 0.2284 Acc: 0.8971\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 0.3864 Acc: 0.8504\n",
      "val Loss: 0.2668 Acc: 0.9012\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 0.3673 Acc: 0.8607\n",
      "val Loss: 0.2497 Acc: 0.9095\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 0.4126 Acc: 0.8431\n",
      "val Loss: 0.2461 Acc: 0.9095\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 0.3399 Acc: 0.8638\n",
      "val Loss: 0.2478 Acc: 0.9136\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 0.3781 Acc: 0.8452\n",
      "val Loss: 0.3278 Acc: 0.8724\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 0.4172 Acc: 0.8400\n",
      "val Loss: 0.2218 Acc: 0.9300\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 0.4572 Acc: 0.8359\n",
      "val Loss: 0.2645 Acc: 0.9012\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 0.3824 Acc: 0.8504\n",
      "val Loss: 0.2270 Acc: 0.9177\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 0.3511 Acc: 0.8689\n",
      "val Loss: 0.4484 Acc: 0.7984\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 0.3511 Acc: 0.8638\n",
      "val Loss: 0.2515 Acc: 0.9095\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 0.4036 Acc: 0.8411\n",
      "val Loss: 0.2056 Acc: 0.9342\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 0.3867 Acc: 0.8596\n",
      "val Loss: 0.3063 Acc: 0.8807\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 0.4193 Acc: 0.8369\n",
      "val Loss: 0.2629 Acc: 0.8889\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 0.4640 Acc: 0.8308\n",
      "val Loss: 0.2519 Acc: 0.9136\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 0.3866 Acc: 0.8617\n",
      "val Loss: 0.2696 Acc: 0.9053\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 0.4250 Acc: 0.8473\n",
      "val Loss: 0.2291 Acc: 0.9095\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 0.4165 Acc: 0.8442\n",
      "val Loss: 0.1994 Acc: 0.9218\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 0.3727 Acc: 0.8545\n",
      "val Loss: 0.2268 Acc: 0.9136\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 0.3871 Acc: 0.8535\n",
      "val Loss: 0.2050 Acc: 0.9177\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 0.3461 Acc: 0.8710\n",
      "val Loss: 0.2172 Acc: 0.9136\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 0.3621 Acc: 0.8669\n",
      "val Loss: 0.2353 Acc: 0.9136\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 0.3799 Acc: 0.8462\n",
      "val Loss: 0.2110 Acc: 0.9177\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 0.3899 Acc: 0.8710\n",
      "val Loss: 0.2210 Acc: 0.9218\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 0.4308 Acc: 0.8380\n",
      "val Loss: 0.2166 Acc: 0.9259\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 0.3590 Acc: 0.8679\n",
      "val Loss: 0.2273 Acc: 0.9136\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 0.4324 Acc: 0.8328\n",
      "val Loss: 0.3100 Acc: 0.8807\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 0.4011 Acc: 0.8442\n",
      "val Loss: 0.2525 Acc: 0.9177\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 0.3901 Acc: 0.8473\n",
      "val Loss: 0.2806 Acc: 0.9136\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 0.3900 Acc: 0.8586\n",
      "val Loss: 0.2317 Acc: 0.9136\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 0.4335 Acc: 0.8442\n",
      "val Loss: 0.2790 Acc: 0.9053\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 0.3571 Acc: 0.8720\n",
      "val Loss: 0.2920 Acc: 0.8889\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 0.3591 Acc: 0.8607\n",
      "val Loss: 0.2473 Acc: 0.9053\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 0.4224 Acc: 0.8246\n",
      "val Loss: 0.3390 Acc: 0.8889\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 0.3795 Acc: 0.8555\n",
      "val Loss: 0.2337 Acc: 0.9136\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 0.3190 Acc: 0.8813\n",
      "val Loss: 0.2566 Acc: 0.8807\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 0.3371 Acc: 0.8720\n",
      "val Loss: 0.2283 Acc: 0.9259\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 0.4139 Acc: 0.8431\n",
      "val Loss: 0.2550 Acc: 0.9012\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 0.3433 Acc: 0.8648\n",
      "val Loss: 0.2186 Acc: 0.9218\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.3908 Acc: 0.8535\n",
      "val Loss: 0.2393 Acc: 0.9095\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 0.4069 Acc: 0.8586\n",
      "val Loss: 0.1930 Acc: 0.9342\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 0.4355 Acc: 0.8400\n",
      "val Loss: 0.2995 Acc: 0.8724\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 0.3704 Acc: 0.8566\n",
      "val Loss: 0.2407 Acc: 0.8971\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.3362 Acc: 0.8689\n",
      "val Loss: 0.2453 Acc: 0.9012\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.4068 Acc: 0.8555\n",
      "val Loss: 0.3395 Acc: 0.8765\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.4111 Acc: 0.8504\n",
      "val Loss: 0.2243 Acc: 0.9136\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.4043 Acc: 0.8431\n",
      "val Loss: 0.2461 Acc: 0.9218\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.3899 Acc: 0.8421\n",
      "val Loss: 0.2139 Acc: 0.9012\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.3587 Acc: 0.8566\n",
      "val Loss: 0.2165 Acc: 0.9012\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.4465 Acc: 0.8297\n",
      "val Loss: 0.1979 Acc: 0.9342\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.4191 Acc: 0.8390\n",
      "val Loss: 0.2986 Acc: 0.8683\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.4023 Acc: 0.8473\n",
      "val Loss: 0.3164 Acc: 0.8724\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.4032 Acc: 0.8504\n",
      "val Loss: 0.2282 Acc: 0.9136\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.3816 Acc: 0.8524\n",
      "val Loss: 0.3258 Acc: 0.8724\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.3550 Acc: 0.8638\n",
      "val Loss: 0.2828 Acc: 0.8724\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.3524 Acc: 0.8669\n",
      "val Loss: 0.2460 Acc: 0.8971\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.4939 Acc: 0.8153\n",
      "val Loss: 0.2666 Acc: 0.8971\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.4262 Acc: 0.8442\n",
      "val Loss: 0.4487 Acc: 0.8272\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.4339 Acc: 0.8390\n",
      "val Loss: 0.3194 Acc: 0.8724\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.3990 Acc: 0.8380\n",
      "val Loss: 0.2326 Acc: 0.9012\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.4444 Acc: 0.8359\n",
      "val Loss: 0.2863 Acc: 0.8971\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.4416 Acc: 0.8380\n",
      "val Loss: 0.2785 Acc: 0.8765\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.3545 Acc: 0.8679\n",
      "val Loss: 0.2370 Acc: 0.9136\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.4504 Acc: 0.8359\n",
      "val Loss: 0.2410 Acc: 0.9136\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.3706 Acc: 0.8669\n",
      "val Loss: 0.2840 Acc: 0.8930\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.4016 Acc: 0.8596\n",
      "val Loss: 0.2952 Acc: 0.8971\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.3659 Acc: 0.8658\n",
      "val Loss: 0.2541 Acc: 0.9012\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 0.4097 Acc: 0.8607\n",
      "val Loss: 0.2952 Acc: 0.8848\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 0.4169 Acc: 0.8452\n",
      "val Loss: 0.2861 Acc: 0.8807\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 0.3778 Acc: 0.8607\n",
      "val Loss: 0.2278 Acc: 0.9177\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 0.3663 Acc: 0.8514\n",
      "val Loss: 0.3352 Acc: 0.8848\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 0.3579 Acc: 0.8524\n",
      "val Loss: 0.2551 Acc: 0.8971\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 0.4347 Acc: 0.8545\n",
      "val Loss: 0.2498 Acc: 0.9177\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 0.3951 Acc: 0.8617\n",
      "val Loss: 0.2572 Acc: 0.8807\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 0.3347 Acc: 0.8710\n",
      "val Loss: 0.2523 Acc: 0.9053\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 0.3909 Acc: 0.8359\n",
      "val Loss: 0.2305 Acc: 0.9218\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 0.3305 Acc: 0.8751\n",
      "val Loss: 0.3264 Acc: 0.8724\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 0.4156 Acc: 0.8504\n",
      "val Loss: 0.3370 Acc: 0.8724\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 0.4219 Acc: 0.8442\n",
      "val Loss: 0.2350 Acc: 0.9177\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 0.3570 Acc: 0.8669\n",
      "val Loss: 0.3135 Acc: 0.8848\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 0.3817 Acc: 0.8462\n",
      "val Loss: 0.3184 Acc: 0.8807\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 0.3704 Acc: 0.8586\n",
      "val Loss: 0.2847 Acc: 0.8889\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 0.3834 Acc: 0.8452\n",
      "val Loss: 0.2732 Acc: 0.8930\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 0.3732 Acc: 0.8586\n",
      "val Loss: 0.5300 Acc: 0.8230\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 0.4077 Acc: 0.8452\n",
      "val Loss: 0.3587 Acc: 0.8642\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 0.4329 Acc: 0.8297\n",
      "val Loss: 0.2495 Acc: 0.9012\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 0.3886 Acc: 0.8473\n",
      "val Loss: 0.2309 Acc: 0.9136\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 0.3999 Acc: 0.8421\n",
      "val Loss: 0.3184 Acc: 0.8724\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 0.3820 Acc: 0.8504\n",
      "val Loss: 0.2528 Acc: 0.9218\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 0.3673 Acc: 0.8586\n",
      "val Loss: 0.2153 Acc: 0.9136\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 0.4137 Acc: 0.8411\n",
      "val Loss: 0.3829 Acc: 0.8477\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 0.3737 Acc: 0.8535\n",
      "val Loss: 0.2547 Acc: 0.8971\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 0.3707 Acc: 0.8617\n",
      "val Loss: 0.2404 Acc: 0.9136\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 0.4605 Acc: 0.8277\n",
      "val Loss: 0.3201 Acc: 0.8807\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4362 Acc: 0.8411\n",
      "val Loss: 0.3043 Acc: 0.8765\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 0.4396 Acc: 0.8369\n",
      "val Loss: 0.2956 Acc: 0.8889\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 0.5003 Acc: 0.8194\n",
      "val Loss: 0.3065 Acc: 0.8848\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 0.3771 Acc: 0.8658\n",
      "val Loss: 0.4242 Acc: 0.8436\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 0.4316 Acc: 0.8400\n",
      "val Loss: 0.2358 Acc: 0.9136\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 0.3628 Acc: 0.8555\n",
      "val Loss: 0.2300 Acc: 0.9218\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 0.4039 Acc: 0.8400\n",
      "val Loss: 0.4032 Acc: 0.8395\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 0.3671 Acc: 0.8679\n",
      "val Loss: 0.3530 Acc: 0.8642\n",
      "\n",
      "Training complete in 100m 57s\n",
      "Best val Acc: 0.938272\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, \n",
    "                             optimizer_ft, num_epochs=num_epochs, \n",
    "                             is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
